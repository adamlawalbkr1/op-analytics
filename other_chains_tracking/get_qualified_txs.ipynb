{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get qualified txs\n"
     ]
    }
   ],
   "source": [
    "print('get qualified txs')\n",
    "import sys\n",
    "sys.path.append(\"../helper_functions\")\n",
    "import duneapi_utils as d\n",
    "import flipside_utils as f\n",
    "import clickhouse_utils as ch\n",
    "import csv_utils as cu\n",
    "import google_bq_utils as bqu\n",
    "import opstack_metadata_utils as ops\n",
    "sys.path.pop()\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import clickhouse_connect as cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = ops.get_op_stack_metadata_by_data_source('flipside')\n",
    "chain_configs = ops.generate_op_stack_chain_config_query_list()\n",
    "\n",
    "# Get All Chain IDs in our metadata list & DB\n",
    "# Commented out to read from Flip & CH responses\n",
    "# chain_ids_string = ops.gen_chain_ids_list_for_param(chain_configs['mainnet_chain_id'])\n",
    "\n",
    "# display(chain_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "ch_client = ch.connect_to_clickhouse_db() #Default is OPLabs DB\n",
    "\n",
    "query_name = 'daily_evms_qualified_txs_counts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = [\n",
    "        'dt','blockchain','name','layer','chain_id'\n",
    "        , 'num_raw_txs', 'num_success_txs','num_qualified_txs','source'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "trailing_days = 90\n",
    "\n",
    "# flipside_configs = chain_configs[chain_configs['source'] == 'flipside']\n",
    "clickhouse_configs = chain_configs[chain_configs['source'] == 'oplabs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# print('     flipside runs')\n",
    "# flip_dfs = []\n",
    "\n",
    "# with open(os.path.join(\"inputs/sql/flipside_bychain.sql\"), \"r\") as file:\n",
    "#     og_query = file.read()\n",
    "\n",
    "# for index, chain in flipside_configs.iterrows():\n",
    "#     print('     flipside: ' + chain['blockchain'])\n",
    "#     query = og_query\n",
    "#     # Pass in Params to the query\n",
    "#     query = query.replace(\"@blockchain@\", chain['blockchain'])\n",
    "#     query = query.replace(\"@chain_id@\", str(chain['mainnet_chain_id']))\n",
    "#     query = query.replace(\"@name@\", chain['display_name'])\n",
    "#     query = query.replace(\"@layer@\", chain['chain_layer'])\n",
    "#     query = query.replace(\"@trailing_days@\", str(trailing_days))\n",
    "    \n",
    "#     try:\n",
    "#         df = f.query_to_df(query)\n",
    "#         flip_dfs.append(df)\n",
    "#     except Exception as e:  # Use FlipsideError if available instead of Exception\n",
    "#         print(f\"Error querying Flipside for {chain['blockchain']}: {str(e)}\")\n",
    "#         print(\"Skipping this chain due to API credit limitation or other issues.\")\n",
    "#         continue\n",
    "\n",
    "# if flip_dfs:\n",
    "#     flip = pd.concat(flip_dfs)\n",
    "#     flip['source'] = 'flipside'\n",
    "#     flip['dt'] = pd.to_datetime(flip['dt']).dt.tz_localize(None)\n",
    "#     flip = flip[col_list]\n",
    "# else:\n",
    "#     print(\"No data was retrieved from Flipside. The resulting DataFrame will be empty.\")\n",
    "#     flip = pd.DataFrame(columns=col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     clickhouse runs\n",
      "clickhouse: op\n",
      "clickhouse: zora\n",
      "clickhouse: base\n",
      "unable to process base\n",
      "clickhouse: mode\n",
      "clickhouse: lisk\n",
      "clickhouse: metal\n",
      "clickhouse: mint\n",
      "clickhouse: fraxtal\n",
      "clickhouse: redstone\n",
      "clickhouse: cyber\n",
      "clickhouse: swan\n"
     ]
    }
   ],
   "source": [
    "# Run Clickhouse\n",
    "print('     clickhouse runs')\n",
    "ch_dfs = []\n",
    "with open(os.path.join(\"inputs/sql/goldsky_bychain.sql\"), \"r\") as file:\n",
    "                        og_query = file.read()\n",
    "\n",
    "for index, chain in clickhouse_configs.iterrows():\n",
    "        print(     'clickhouse: ' + chain['blockchain'])\n",
    "        query = og_query\n",
    "        #Pass in Params to the query\n",
    "        query = query.replace(\"@blockchain@\", chain['blockchain'])\n",
    "        if chain['blockchain'] == 'bob':\n",
    "                query = query.replace(\"chain_id, --db chain_id\", str(chain['mainnet_chain_id']) + \" as chain_id,\")\n",
    "                # query = query.replace(\"@chain_id@\", str(chain['mainnet_chain_id']))\n",
    "        query = query.replace(\"@name@\", chain['display_name'])\n",
    "        query = query.replace(\"@layer@\", chain['chain_layer'])\n",
    "        query = query.replace(\"@trailing_days@\", str(trailing_days))\n",
    "        try:\n",
    "                df = ch_client.query_df(query)\n",
    "                ch_dfs.append(df)\n",
    "        except:\n",
    "                print('unable to process ' + chain['blockchain'])\n",
    "if ch_dfs:\n",
    "    ch = pd.concat(ch_dfs)\n",
    "    ch['source'] = 'goldsky'\n",
    "    ch['dt'] = pd.to_datetime(ch['dt']).dt.tz_localize(None)\n",
    "    ch = ch[col_list]\n",
    "else:\n",
    "    print(\"No data was retrieved from Goldsky. The resulting DataFrame will be empty.\")\n",
    "    ch = pd.DataFrame(columns=col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7560,1135,10,254,252,185,1750,690,34443,7777777\n"
     ]
    }
   ],
   "source": [
    "# Get Chains we already have data for & don't need to run in Dune\n",
    "dataframes = [ch]#, flip]\n",
    "\n",
    "chain_ids_string = ops.get_unique_chain_ids_from_dfs(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-26 18:59:09.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mduneapi_utils\u001b[0m:\u001b[36mget_dune_data\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mResults available at https://dune.com/queries/3740822?trailing_days=180&list_chain_ids=7560%2C1135%2C10%2C254%2C252%2C185%2C1750%2C690%2C34443%2C7777777\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     dune runs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-26 18:59:09,948 ERROR dune_client.models Can't build ResultsResponse from {'error': 'not found: No execution found for the latest version of the given query'} due to KeyError: 'execution_id'\n",
      "2024-08-26 18:59:09,950 INFO dune_client.api.base executing 3740822 on large cluster\n",
      "2024-08-26 18:59:10,276 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.PENDING (queue position: 1)\n",
      "2024-08-26 18:59:11,447 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.PENDING (queue position: 1)\n",
      "2024-08-26 18:59:12,609 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.PENDING (queue position: 1)\n",
      "2024-08-26 18:59:13,771 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.PENDING (queue position: 1)\n",
      "2024-08-26 18:59:14,939 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.PENDING (queue position: 1)\n",
      "2024-08-26 18:59:16,106 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.PENDING (queue position: 1)\n",
      "2024-08-26 18:59:17,276 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.PENDING (queue position: 1)\n",
      "2024-08-26 18:59:18,441 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.PENDING (queue position: 1)\n",
      "2024-08-26 18:59:19,678 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.PENDING (queue position: 1)\n",
      "2024-08-26 18:59:20,850 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.PENDING (queue position: 1)\n",
      "2024-08-26 18:59:22,134 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.PENDING (queue position: 1)\n",
      "2024-08-26 18:59:23,365 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.PENDING (queue position: 1)\n",
      "2024-08-26 18:59:24,526 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.PENDING (queue position: 1)\n",
      "2024-08-26 18:59:25,691 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.PENDING (queue position: 1)\n",
      "2024-08-26 18:59:26,863 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.PENDING (queue position: 1)\n",
      "2024-08-26 18:59:28,035 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.PENDING (queue position: 1)\n",
      "2024-08-26 18:59:29,206 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.PENDING (queue position: 1)\n",
      "2024-08-26 18:59:30,374 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.PENDING (queue position: 1)\n",
      "2024-08-26 18:59:31,547 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.PENDING (queue position: 1)\n",
      "2024-08-26 18:59:32,706 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.PENDING (queue position: 1)\n",
      "2024-08-26 18:59:33,871 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.PENDING (queue position: 1)\n",
      "2024-08-26 18:59:35,030 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.PENDING (queue position: 1)\n",
      "2024-08-26 18:59:36,191 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.EXECUTING\n",
      "2024-08-26 18:59:37,442 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.EXECUTING\n",
      "2024-08-26 18:59:38,625 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.EXECUTING\n",
      "2024-08-26 18:59:39,794 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.EXECUTING\n",
      "2024-08-26 18:59:41,078 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.EXECUTING\n",
      "2024-08-26 18:59:42,238 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.EXECUTING\n",
      "2024-08-26 18:59:43,402 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.EXECUTING\n",
      "2024-08-26 18:59:44,573 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.EXECUTING\n",
      "2024-08-26 18:59:45,744 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.EXECUTING\n",
      "2024-08-26 18:59:46,913 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.EXECUTING\n",
      "2024-08-26 18:59:48,077 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.EXECUTING\n",
      "2024-08-26 18:59:49,231 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.EXECUTING\n",
      "2024-08-26 18:59:50,495 INFO dune_client.api.base waiting for query execution 01J68EM9MA3MKWQMNP15WR51FM to complete: ExecutionState.EXECUTING\n"
     ]
    }
   ],
   "source": [
    "# Run Dune\n",
    "print('     dune runs')\n",
    "days_param = d.generate_query_parameter(input=trailing_days,field_name='trailing_days',dtype='number')\n",
    "chain_ids_param = d.generate_query_parameter(input=chain_ids_string,field_name='list_chain_ids',dtype='text')\n",
    "\n",
    "dune_df = d.get_dune_data(query_id = 3740822, #https://dune.com/queries/3740822\n",
    "    name = \"dune_evms_qualified_txs\",\n",
    "    path = \"outputs\",\n",
    "    performance=\"large\",\n",
    "    params = [days_param,chain_ids_param],\n",
    "    num_hours_to_rerun=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not dune_df.empty:\n",
    "    dune_df['source'] = 'dune'\n",
    "    dune_df['dt'] = pd.to_datetime(dune_df['dt']).dt.tz_localize(None)\n",
    "    dune_df = dune_df[col_list]\n",
    "else:\n",
    "    print(\"No data was retrieved from Dune. The resulting DataFrame will be empty.\")\n",
    "    dune_df = pd.DataFrame(columns=col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ch shape: {ch.shape}\")\n",
    "# print(f\"flip shape: {flip.shape}\")\n",
    "print(f\"dune_df shape: {dune_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Combine dfs\n",
    "# final_df = pd.concat([ch, dune_df])#, flip])\n",
    "final_df = pd.concat([ch, dune_df], axis=0, ignore_index=True)\n",
    "\n",
    "# Remove Dupes\n",
    "final_df = final_df.drop_duplicates(subset=['chain_id','dt'], keep='first')\n",
    "\n",
    "print(f\"final_df shape: {final_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opstack_metadata = pd.read_csv('../op_chains_tracking/outputs/chain_metadata.csv')\n",
    "\n",
    "opstack_metadata['chain_id'] = opstack_metadata['mainnet_chain_id']\n",
    "\n",
    "meta_cols = ['is_op_chain','op_based_version', 'chain_id', 'alignment','chain_name', 'display_name']\n",
    "\n",
    "# print(\"Columns in opstack_metadata:\", opstack_metadata.columns)\n",
    "# print(\"Columns in opstack_metadata[meta_cols]:\", opstack_metadata[meta_cols].columns)\n",
    "# print(\"Columns in final_df:\", final_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "final_enriched_df = final_df.merge(opstack_metadata[meta_cols], on='chain_id', how = 'left')\n",
    "final_enriched_df['alignment'] = final_enriched_df['alignment'].fillna('Other EVMs')\n",
    "final_enriched_df['is_op_chain'] = final_enriched_df['is_op_chain'].fillna(False)\n",
    "final_enriched_df['display_name'] = final_enriched_df['display_name'].fillna(final_enriched_df['name'])\n",
    "\n",
    "final_enriched_df = final_enriched_df.drop(columns=['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "final_enriched_df.sort_values(by=['dt','blockchain'], ascending =[False, False], inplace = True)\n",
    "\n",
    "final_enriched_df.to_csv('outputs/'+query_name+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_enriched_df['chain_id'] = final_enriched_df['chain_id'].astype(int)\n",
    "final_enriched_df['num_raw_txs'] = final_enriched_df['num_raw_txs'].astype(int)\n",
    "final_enriched_df['num_success_txs'] = final_enriched_df['num_success_txs'].astype(int)\n",
    "final_enriched_df['num_qualified_txs'] = final_enriched_df['num_qualified_txs'].fillna(0)\n",
    "final_enriched_df['num_qualified_txs'] = final_enriched_df['num_qualified_txs'].astype(int)\n",
    "# final_enriched_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BQ Upload\n",
    "bqu.append_and_upsert_df_to_bq_table(final_enriched_df, query_name, unique_keys = ['chain_id','dt'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
