{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of materialized view names\n",
    "mv_names = [\n",
    "        # in order of build\n",
    "        'erc20_transfers',\n",
    "        'native_eth_transfers',\n",
    "        # 'transactions_unique',\n",
    "\n",
    "        'daily_aggregate_transactions_to',\n",
    "        'across_bridging_txs_v3'\n",
    "        ]\n",
    "set_days_batch_size = 7 #30\n",
    "\n",
    "optimize_all = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "import traceback\n",
    "sys.path.append(\"../../helper_functions\")\n",
    "import clickhouse_utils as ch\n",
    "import opstack_metadata_utils as ops\n",
    "import goldsky_db_utils as gsb\n",
    "sys.path.pop()\n",
    "client = ch.connect_to_clickhouse_db()\n",
    "\n",
    "import dotenv\n",
    "import os\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chain_name</th>\n",
       "      <th>display_name</th>\n",
       "      <th>mainnet_chain_id</th>\n",
       "      <th>chain_layer</th>\n",
       "      <th>alignment</th>\n",
       "      <th>da_layer</th>\n",
       "      <th>output_root_layer</th>\n",
       "      <th>gas_token</th>\n",
       "      <th>block_time_sec</th>\n",
       "      <th>public_mainnet_launch_date</th>\n",
       "      <th>op_chain_start</th>\n",
       "      <th>blockchain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>op</td>\n",
       "      <td>OP Mainnet</td>\n",
       "      <td>10</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2021-06-23</td>\n",
       "      <td>2021-06-23</td>\n",
       "      <td>op</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zora</td>\n",
       "      <td>Zora</td>\n",
       "      <td>7777777</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2023-06-14</td>\n",
       "      <td>2023-06-14</td>\n",
       "      <td>zora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>base</td>\n",
       "      <td>Base</td>\n",
       "      <td>8453</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2023-08-09</td>\n",
       "      <td>2023-06-15</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mode</td>\n",
       "      <td>Mode</td>\n",
       "      <td>34443</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lisk</td>\n",
       "      <td>Lisk</td>\n",
       "      <td>1135</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-05-03</td>\n",
       "      <td>2024-05-03</td>\n",
       "      <td>lisk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>metal</td>\n",
       "      <td>Metal</td>\n",
       "      <td>1750</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-05-09</td>\n",
       "      <td>2024-05-09</td>\n",
       "      <td>metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mint</td>\n",
       "      <td>Mint</td>\n",
       "      <td>185</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-05-15</td>\n",
       "      <td>2024-05-15</td>\n",
       "      <td>mint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>orderly</td>\n",
       "      <td>Orderly</td>\n",
       "      <td>291</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>celestia</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2023-10-16</td>\n",
       "      <td>2024-07-09</td>\n",
       "      <td>orderly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fraxtal</td>\n",
       "      <td>Fraxtal</td>\n",
       "      <td>252</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>fraxtalda</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>frxETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-03-11</td>\n",
       "      <td>2024-03-11</td>\n",
       "      <td>fraxtal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>redstone</td>\n",
       "      <td>Redstone</td>\n",
       "      <td>690</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>op-plasma</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>redstone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cyber</td>\n",
       "      <td>Cyber</td>\n",
       "      <td>7560</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>eigenda</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-05-15</td>\n",
       "      <td>2024-05-15</td>\n",
       "      <td>cyber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ham</td>\n",
       "      <td>5112</td>\n",
       "      <td>L3</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>unknown</td>\n",
       "      <td>base</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-06-05</td>\n",
       "      <td>2024-06-05</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>lyra</td>\n",
       "      <td>Derive</td>\n",
       "      <td>957</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>celestia</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2023-12-13</td>\n",
       "      <td>2024-06-18</td>\n",
       "      <td>lyra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bob</td>\n",
       "      <td>BOB (Build on Bitcoin)</td>\n",
       "      <td>60808</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>ethereum bitcoin</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>2024-08-02</td>\n",
       "      <td>bob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>swan</td>\n",
       "      <td>SwanChain</td>\n",
       "      <td>254</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-07-02</td>\n",
       "      <td>2024-07-02</td>\n",
       "      <td>swan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>polynomial</td>\n",
       "      <td>Polynomial Chain</td>\n",
       "      <td>8008</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-06-10</td>\n",
       "      <td>2024-06-10</td>\n",
       "      <td>polynomial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>race</td>\n",
       "      <td>Race</td>\n",
       "      <td>6805</td>\n",
       "      <td>L2</td>\n",
       "      <td>OP Chain</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-07-08</td>\n",
       "      <td>2024-07-08</td>\n",
       "      <td>race</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    chain_name            display_name mainnet_chain_id chain_layer alignment  \\\n",
       "0           op              OP Mainnet               10          L2  OP Chain   \n",
       "1         zora                    Zora          7777777          L2  OP Chain   \n",
       "2         base                    Base             8453          L2  OP Chain   \n",
       "3         mode                    Mode            34443          L2  OP Chain   \n",
       "5         lisk                    Lisk             1135          L2  OP Chain   \n",
       "6        metal                   Metal             1750          L2  OP Chain   \n",
       "7         mint                    Mint              185          L2  OP Chain   \n",
       "12     orderly                 Orderly              291          L2  OP Chain   \n",
       "13     fraxtal                 Fraxtal              252          L2  OP Chain   \n",
       "14    redstone                Redstone              690          L2  OP Chain   \n",
       "15       cyber                   Cyber             7560          L2  OP Chain   \n",
       "16         ham                     Ham             5112          L3  OP Chain   \n",
       "19        lyra                  Derive              957          L2  OP Chain   \n",
       "20         bob  BOB (Build on Bitcoin)            60808          L2  OP Chain   \n",
       "39        swan               SwanChain              254          L2  OP Chain   \n",
       "58  polynomial        Polynomial Chain             8008          L2  OP Chain   \n",
       "60        race                    Race             6805          L2  OP Chain   \n",
       "\n",
       "            da_layer output_root_layer gas_token  block_time_sec  \\\n",
       "0           ethereum          ethereum       ETH             2.0   \n",
       "1           ethereum          ethereum       ETH             2.0   \n",
       "2           ethereum          ethereum       ETH             2.0   \n",
       "3           ethereum          ethereum       ETH             2.0   \n",
       "5           ethereum          ethereum       ETH             2.0   \n",
       "6           ethereum          ethereum       ETH             2.0   \n",
       "7           ethereum          ethereum       ETH             2.0   \n",
       "12          celestia          ethereum       ETH             2.0   \n",
       "13         fraxtalda          ethereum    frxETH             2.0   \n",
       "14         op-plasma          ethereum       ETH             2.0   \n",
       "15           eigenda          ethereum       ETH             2.0   \n",
       "16           unknown              base       ETH             2.0   \n",
       "19          celestia          ethereum       ETH             2.0   \n",
       "20  ethereum bitcoin          ethereum       ETH             2.0   \n",
       "39          ethereum          ethereum       ETH             2.0   \n",
       "58          ethereum          ethereum       ETH             2.0   \n",
       "60          ethereum          ethereum       ETH             2.0   \n",
       "\n",
       "   public_mainnet_launch_date op_chain_start  blockchain  \n",
       "0                  2021-06-23     2021-06-23          op  \n",
       "1                  2023-06-14     2023-06-14        zora  \n",
       "2                  2023-08-09     2023-06-15        base  \n",
       "3                  2024-01-31     2024-01-31        mode  \n",
       "5                  2024-05-03     2024-05-03        lisk  \n",
       "6                  2024-05-09     2024-05-09       metal  \n",
       "7                  2024-05-15     2024-05-15        mint  \n",
       "12                 2023-10-16     2024-07-09     orderly  \n",
       "13                 2024-03-11     2024-03-11     fraxtal  \n",
       "14                 2024-05-01     2024-05-01    redstone  \n",
       "15                 2024-05-15     2024-05-15       cyber  \n",
       "16                 2024-06-05     2024-06-05         ham  \n",
       "19                 2023-12-13     2024-06-18        lyra  \n",
       "20                 2024-05-01     2024-08-02         bob  \n",
       "39                 2024-07-02     2024-07-02        swan  \n",
       "58                 2024-06-10     2024-06-10  polynomial  \n",
       "60                 2024-07-08     2024-07-08        race  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Chain List\n",
    "chain_configs = ops.get_superchain_metadata_by_data_source('oplabs') # OPLabs db\n",
    "\n",
    "if client is None:\n",
    "        client = ch.connect_to_clickhouse_db()\n",
    "\n",
    "# Function to create ClickHouse view\n",
    "def get_chain_names_from_df(df):\n",
    "    return df['blockchain'].dropna().unique().tolist()\n",
    "\n",
    "# chain_configs = chain_configs[chain_configs['chain_name'] == 'bob']\n",
    "\n",
    "chain_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-13\n"
     ]
    }
   ],
   "source": [
    "# List of chains\n",
    "# chains = get_chain_names_from_df(chain_configs)\n",
    "\n",
    "# Start date for backfilling\n",
    "# start_date = datetime.date(2021, 11, 1)\n",
    "start_date = datetime.date(2024, 5, 1)\n",
    "end_date = datetime.date.today() + datetime.timedelta(days=1)\n",
    "\n",
    "print(end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_from_file(mv_name):\n",
    "    try:\n",
    "        # Try to get the directory of the current script\n",
    "        script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    except NameError:\n",
    "        # If __file__ is not defined (e.g., in Jupyter), use the current working directory\n",
    "        script_dir = os.getcwd()\n",
    "    \n",
    "    query_file_path = os.path.join(script_dir, 'mv_inputs', f'{mv_name}.sql')\n",
    "    # print(f\"Attempting to read query from: {query_file_path}\")\n",
    "    \n",
    "    try:\n",
    "        with open(query_file_path, 'r') as file:\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Query file not found: {query_file_path}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_optimize_on_insert(option_int = 1):\n",
    "    client.command(f\"\"\"\n",
    "        SET optimize_on_insert = {option_int};\n",
    "        \"\"\")\n",
    "    print(f\"Set optimize_on_insert = {option_int}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import clickhouse_connect\n",
    "from clickhouse_connect.driver.exceptions import ClickHouseError\n",
    "\n",
    "def create_materialized_view(client, chain, mv_name, block_time = 2):\n",
    "    table_view_name = f'{chain}_{mv_name}'\n",
    "    full_view_name = f'{chain}_{mv_name}_mv'\n",
    "    create_file_name = f'{mv_name}_create'\n",
    "    print(full_view_name)\n",
    "    \n",
    "    # Check if create file exists\n",
    "    if not os.path.exists(f'mv_inputs/{create_file_name}.sql'):\n",
    "        print(f\"Table create file {create_file_name}.sql does not exist. Skipping table creation.\")\n",
    "    else:\n",
    "        try:\n",
    "            # Check if table already exists\n",
    "            result = client.query(f\"SHOW TABLES LIKE '{table_view_name}'\")\n",
    "            result_rows = list(result.result_rows)\n",
    "            if result_rows:\n",
    "                print(f\"Table {table_view_name} already exists. Skipping creation.\")\n",
    "            else:\n",
    "                # Create the table\n",
    "                create_query = get_query_from_file(create_file_name)\n",
    "                create_query = create_query.format(chain=chain, view_name=table_view_name)\n",
    "                client.command(create_query)\n",
    "                print(f\"Created table {table_view_name}\")\n",
    "        except ClickHouseError as e:\n",
    "            print(f\"Error creating table {table_view_name}: {str(e)}\")\n",
    "            return  # Exit the function if table creation fails\n",
    "\n",
    "    try:\n",
    "        # Check if view already exists\n",
    "        result = client.query(f\"SHOW TABLES LIKE '{full_view_name}'\")\n",
    "        result_rows = list(result.result_rows)\n",
    "        if result_rows:\n",
    "            print(f\"Materialized view {full_view_name} already exists. Skipping creation.\")\n",
    "            return\n",
    "\n",
    "        query_template = get_query_from_file(f'{mv_name}_mv')\n",
    "        query = query_template.format(chain=chain, view_name=full_view_name, table_name=table_view_name, block_time_sec=block_time)\n",
    "        query = gsb.process_goldsky_sql(query)\n",
    "        # print(query)\n",
    "        client.command(query)\n",
    "        print(f\"Created materialized view {full_view_name}\")\n",
    "    except ClickHouseError as e:\n",
    "        print(f\"Error creating materialized view {full_view_name}: {str(e)}\")\n",
    "\n",
    "\n",
    "def ensure_backfill_tracking_table_exists(client):\n",
    "    check_table_query = \"\"\"\n",
    "    SELECT 1 FROM system.tables \n",
    "    WHERE database = currentDatabase() AND name = 'backfill_tracking'\n",
    "    \"\"\"\n",
    "    result = client.query(check_table_query)\n",
    "    \n",
    "    if not result.result_rows:\n",
    "        create_table_query = \"\"\"\n",
    "        CREATE TABLE backfill_tracking (\n",
    "            chain String,\n",
    "            mv_name String,\n",
    "            start_date Date,\n",
    "            end_date Date\n",
    "        ) ENGINE = MergeTree()\n",
    "        ORDER BY (chain, mv_name, start_date)\n",
    "        \"\"\"\n",
    "        client.command(create_table_query)\n",
    "        print(\"Created backfill_tracking table.\")\n",
    "    else:\n",
    "        print(\"backfill_tracking table already exists.\")\n",
    "\n",
    "def backfill_data(client, chain, mv_name, end_date = end_date, block_time = 2):\n",
    "    full_view_name = f'{chain}_{mv_name}_mv'\n",
    "    full_table_name = f'{chain}_{mv_name}'\n",
    "    current_date_q = f\"SELECT DATE_TRUNC('day',MIN(timestamp)) AS start_dt FROM {chain}_blocks WHERE number = 1 AND is_deleted = 0\"\n",
    "    current_date = client.query(current_date_q).result_rows[0][0].date()\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        print(f\"{chain} - {mv_name}: Current date: {current_date} - End Date: {end_date}\")\n",
    "        attempts = 1\n",
    "        is_success = 0\n",
    "        days_batch_size = set_days_batch_size\n",
    "        \n",
    "        while (is_success == 0) & (attempts < 3) & (current_date + datetime.timedelta(days=days_batch_size) <= end_date):\n",
    "            batch_size = datetime.timedelta(days=days_batch_size)\n",
    "            print(f\"attempt: {attempts}\")\n",
    "            batch_end = min(current_date + batch_size, end_date)\n",
    "            # print('checking backfill tracking')\n",
    "            # Check if this range has been backfilled\n",
    "            check_query = f\"\"\"\n",
    "            SELECT MAX(start_date) AS latest_fill_start\n",
    "            FROM backfill_tracking\n",
    "            WHERE chain = '{chain}'\n",
    "            AND mv_name = '{mv_name}'\n",
    "            HAVING \n",
    "                MIN(start_date) <= toDate('{current_date}')\n",
    "            AND MAX(end_date) >= toDate('{batch_end}')\n",
    "            LIMIT 1\n",
    "            \"\"\"\n",
    "            result = client.query(check_query)\n",
    "\n",
    "            if result.result_rows: # Get date to start backfilling\n",
    "                latest_fill_start = result.result_rows[0][0]\n",
    "                # print(f\"Latest Fill Result: {latest_fill_start}\")\n",
    "                current_date = max(latest_fill_start, current_date)\n",
    "                batch_end = min(current_date + batch_size, end_date)\n",
    "            else:\n",
    "                print(\"no backfill exists\")\n",
    "            # print(f\"Fill start: {current_date}\")\n",
    "\n",
    "            # print(check_query)\n",
    "            # print(result.result_rows)\n",
    "            #Check if data already exists\n",
    "\n",
    "\n",
    "            if not result.result_rows:\n",
    "                # No record of backfill, proceed\n",
    "                query_template = get_query_from_file(f'{mv_name}_backfill')\n",
    "                query = query_template.format(\n",
    "                    view_name=full_view_name,\n",
    "                    chain=chain,\n",
    "                    start_date=current_date,\n",
    "                    end_date=batch_end,\n",
    "                    table_name = full_table_name,\n",
    "                    block_time_sec = block_time\n",
    "                )\n",
    "                query = gsb.process_goldsky_sql(query)\n",
    "                \n",
    "                # print(query)\n",
    "                try:\n",
    "                    # print(query)\n",
    "                    # set_optimize_on_insert(0) # for runtime\n",
    "                    print(f\"Starting backfill for {full_view_name} from {current_date} to {batch_end}\")\n",
    "                    client.command(query)\n",
    "                    # Record the backfill\n",
    "                    track_query = f\"\"\"\n",
    "                    INSERT INTO backfill_tracking (chain, mv_name, start_date, end_date)\n",
    "                    VALUES ('{chain}', '{mv_name}', toDate('{current_date}'), toDate('{batch_end}'))\n",
    "                    \"\"\"\n",
    "                    client.command(track_query)\n",
    "                    \n",
    "                    print(f\"Backfilled data for {full_view_name} from {current_date} to {batch_end}\")\n",
    "\n",
    "                    # Optimize the newly backfilled partition\n",
    "                    # optimize_partition(client, full_view_name, current_date, batch_end)\n",
    "                    is_success = 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error during backfill for {full_view_name} from {current_date} to {batch_end}: {str(e)}\")\n",
    "                    days_batch_size = 1\n",
    "                    attempts += 1\n",
    "                time.sleep(1)\n",
    "            else:\n",
    "                print(f\"Data already backfilled for {full_view_name} from {current_date} to {batch_end}. Skipping.\")\n",
    "                is_success = 1\n",
    "                # if optimize_all:\n",
    "                #     optimize_partition(client, full_view_name, current_date, batch_end)\n",
    "        # print(f\"Current Date: {current_date}, Batch End: {batch_end}\")\n",
    "        current_date = max(batch_end,current_date) + datetime.timedelta(days=1)\n",
    "        # print(f\"New Current Date: {current_date}\")\n",
    "\n",
    "# def optimize_partition(client, full_view_name, start_date, end_date):\n",
    "#     # First, let's get the actual partition names\n",
    "#     partition_query = f\"\"\"\n",
    "#     SELECT DISTINCT partition\n",
    "#     FROM system.parts\n",
    "#     WHERE table = '{full_view_name.split('.')[-1]}'\n",
    "#       AND database = '{full_view_name.split('.')[0]}'\n",
    "#       AND active\n",
    "#     ORDER BY partition\n",
    "#     \"\"\"\n",
    "#     print(partition_query)\n",
    "#     partitions = [row[0] for row in client.query(partition_query).result_rows]\n",
    "    \n",
    "#     print(f\"Available partitions for {full_view_name}: {partitions}\")\n",
    "\n",
    "#     # Filter partitions within our date range\n",
    "#     start_partition = start_date.strftime('%Y%m')\n",
    "#     end_partition = end_date.strftime('%Y%m')\n",
    "#     partitions_to_optimize = [p for p in partitions if start_partition <= p <= end_partition]\n",
    "\n",
    "#     if not partitions_to_optimize:\n",
    "#         print(f\"No partitions found for {full_view_name} between {start_date} and {end_date}\")\n",
    "#         return\n",
    "\n",
    "#     try:\n",
    "#         for partition in partitions_to_optimize:\n",
    "#             optimize_query = f\"\"\"\n",
    "#             OPTIMIZE TABLE {full_view_name} \n",
    "#             PARTITION '{partition}'\n",
    "#             FINAL SETTINGS max_execution_time = 3000\n",
    "#             \"\"\"\n",
    "#             print(f\"Attempting to optimize {full_view_name} for partition {partition}\")\n",
    "#             client.command(optimize_query)\n",
    "#             print(f\"Successfully optimized partition {partition} for {full_view_name}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error executing OPTIMIZE TABLE for {full_view_name}\")\n",
    "#         print(f\"  Partition: {partition}\")\n",
    "#         print(f\"  Date range: {start_date} to {end_date}\")\n",
    "#         print(f\"  Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_materialized_view(client, chain, mv_name, block_time = 2):\n",
    "    full_view_name = f'{chain}_{mv_name}_mv'\n",
    "    table_name = f'{chain}_{mv_name}'\n",
    "\n",
    "    try:\n",
    "        # Drop the existing materialized view\n",
    "        client.command(f\"DROP TABLE IF EXISTS {full_view_name}\")\n",
    "        # client.command(f\"DROP MATERIALIZED VIEW IF EXISTS {full_view_name}\")\n",
    "        print(f\"Dropped materialized view {full_view_name}\")\n",
    "\n",
    "        # Drop the existing materialized view\n",
    "        client.command(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "        print(f\"Dropped table {table_name}\")\n",
    "\n",
    "        # # Recreate the materialized view using the existing function\n",
    "        # create_materialized_view(client, chain, mv_name, block_time)\n",
    "        # print(f\"Recreated materialized view {full_view_name}\")\n",
    "\n",
    "        # Clear the backfill tracking for this view\n",
    "        client.command(f\"\"\"\n",
    "        ALTER TABLE backfill_tracking \n",
    "        DELETE WHERE chain = '{chain}' AND mv_name = '{mv_name}'\n",
    "        \"\"\")\n",
    "        print(f\"Cleared backfill tracking for {full_view_name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error resetting materialized view {full_view_name}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # To reset a view\n",
    "# for row in chain_configs.itertuples(index=False):\n",
    "#         chain = row.chain_name\n",
    "#         reset_materialized_view(client, chain, 'across_bridging_txs_v3', 2)\n",
    "\n",
    "#reset a single chain\n",
    "# reset_materialized_view(client, 'zora', 'across_bridging_txs_v3', 2)\n",
    "\n",
    "# # # # # # # for mv in mv_names:\n",
    "# # # # # # #         # print(row)\n",
    "# # # # # # #         reset_materialized_view(client, 'bob', mv, 2)\n",
    "\n",
    "\n",
    "# # # Clear all\n",
    "# # # mv_names\n",
    "# # # for row in chain_configs.itertuples(index=False):\n",
    "# # #         for mv in mv_names:\n",
    "# # #                 chain = row.chain_name\n",
    "# # #                 reset_materialized_view(client, chain, mv, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution\n",
    "ensure_backfill_tracking_table_exists(client)\n",
    "\n",
    "for row in chain_configs.itertuples(index=False):\n",
    "\n",
    "    chain = row.chain_name\n",
    "    block_time = row.block_time_sec\n",
    "    print(f\"Processing chain: {chain}\")\n",
    "    for mv_name in mv_names:\n",
    "        \n",
    "        try:\n",
    "            print('create matview')\n",
    "            create_materialized_view(client, chain, mv_name, block_time = block_time)\n",
    "        except:\n",
    "            print('error')\n",
    "        try:\n",
    "            print('create backfill')\n",
    "            backfill_data(client, chain, mv_name, end_date = end_date, block_time = block_time)\n",
    "        except Exception as e:\n",
    "            print('An error occurred:')\n",
    "            print(str(e))\n",
    "            print('Traceback:')\n",
    "            print(traceback.format_exc())\n",
    "        \n",
    "    print(f\"Completed processing for {chain}\")\n",
    "\n",
    "print(\"All chains and views processed successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
